{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50072a53-f90a-48c8-aad8-e11414f26217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#FAFB LNd6: 720575940634984800-->left, 720575940627933336-->right\\n#FAFB 5LNv: 720575940625254636-->left, 720575940619074049-->right\\n#VP5 + SEZ adPN 720575940623617973 -->left, 720575940620445062 -->right\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#FAFB LNd6: 720575940634984800-->left, 720575940627933336-->right\n",
    "#FAFB 5LNv: 720575940625254636-->left, 720575940619074049-->right\n",
    "#VP5 + SEZ adPN 720575940623617973 -->left, 720575940620445062 -->right\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "831291b0-f575-4cd9-9953-ed35281a8ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token succesfully stored.\n",
      "Default dataset set to \"production\".\n"
     ]
    }
   ],
   "source": [
    "from fafbseg import flywire\n",
    "import navis\n",
    "import pandas as pd\n",
    "from collections import deque\n",
    "from tqdm import tqdm\n",
    "token = \"your token\"\n",
    "flywire.set_chunkedgraph_secret(token, overwrite = True)\n",
    "flywire.set_default_dataset('production')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5855402-d5ae-446b-a8c2-8032cba78fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_bidirectional_paths(source, target, max_steps=6, weight_threshold=5, min_steps=2):\n",
    "    \"\"\"\n",
    "    Find candidate paths from source to target using bidirectional search.\n",
    "    \n",
    "    The search expands from the source (forward) by following outgoing edges\n",
    "    and from the target (backward) by following incoming edges.\n",
    "    \n",
    "    Parameters:\n",
    "      - source: Source neuron ID.\n",
    "      - target: Target neuron ID.\n",
    "      - max_steps: Maximum total number of edges allowed (forward_depth + backward_depth).\n",
    "      - weight_threshold: Only consider connections with weight >= this threshold.\n",
    "      - min_steps: Minimum number of edges for a valid path.\n",
    "    \n",
    "    Returns:\n",
    "      A list of candidate paths. Each candidate is a tuple (path, weights) where:\n",
    "         * path: list of neuron IDs from source to target.\n",
    "         * weights: list of synaptic weights for each edge.\n",
    "    \"\"\"\n",
    "    # Initialize forward and backward candidate lists.\n",
    "    # Forward candidates: paths starting at source.\n",
    "    # Backward candidates: paths starting at target.\n",
    "    forward = [([source], [])]\n",
    "    backward = [([target], [])]  # Note: these paths are built from target backward.\n",
    "    \n",
    "    forward_depth = 0\n",
    "    backward_depth = 0\n",
    "    \n",
    "    # The search stops when total depth (forward + backward) reaches max_steps.\n",
    "    while (forward or backward) and (forward_depth + backward_depth < max_steps):\n",
    "        # First, check for intersection between frontiers.\n",
    "        forward_frontier = { path[-1] for path, _ in forward }\n",
    "        backward_frontier = { path[-1] for path, _ in backward }\n",
    "        intersect = forward_frontier.intersection(backward_frontier)\n",
    "        if intersect:\n",
    "            merged_paths = []\n",
    "            for node in intersect:\n",
    "                # For every candidate in forward ending with the intersection node...\n",
    "                for fpath, fweights in [cand for cand in forward if cand[0][-1] == node]:\n",
    "                    # ...and every candidate in backward ending with that node.\n",
    "                    for bpath, bweights in [cand for cand in backward if cand[0][-1] == node]:\n",
    "                        # Merge: fpath + reversed(bpath[:-1]) (avoid duplicating the intersection node)\n",
    "                        merged_path = fpath + list(reversed(bpath[:-1]))\n",
    "                        merged_weights = fweights + list(reversed(bweights))\n",
    "                        if (len(merged_path) - 1) >= min_steps:\n",
    "                            merged_paths.append((merged_path, merged_weights))\n",
    "            if merged_paths:\n",
    "                return merged_paths\n",
    "\n",
    "        # Decide which side to expand next based on the number of candidates.\n",
    "        if len(forward) <= len(backward):\n",
    "            # Expand the forward side.\n",
    "            new_forward = []\n",
    "            frontier_nodes = { path[-1] for path, _ in forward }\n",
    "            # Batch query: get all connectivity for the current forward frontier.\n",
    "            df = flywire.get_connectivity(list(frontier_nodes))\n",
    "            # Keep only rows where the 'pre' is in the frontier.\n",
    "            df = df[df['pre'].isin(frontier_nodes)]\n",
    "            df = df[df['weight'] >= weight_threshold]\n",
    "            for path, weights in forward:\n",
    "                current = path[-1]\n",
    "                sub_df = df[df['pre'] == current]\n",
    "                for row in sub_df.itertuples(index=False):\n",
    "                    post = row.post\n",
    "                    w = row.weight\n",
    "                    # Avoid cycles within the forward search.\n",
    "                    if post in path:\n",
    "                        continue\n",
    "                    new_forward.append((path + [post], weights + [w]))\n",
    "            forward = new_forward\n",
    "            forward_depth += 1\n",
    "        else:\n",
    "            # Expand the backward side.\n",
    "            new_backward = []\n",
    "            frontier_nodes = { path[-1] for path, _ in backward }\n",
    "            # For backward, we need to get connectivity where the candidate is in the 'post' column.\n",
    "            df = flywire.get_connectivity(list(frontier_nodes))\n",
    "            df = df[df['post'].isin(frontier_nodes)]\n",
    "            df = df[df['weight'] >= weight_threshold]\n",
    "            for path, weights in backward:\n",
    "                current = path[-1]\n",
    "                sub_df = df[df['post'] == current]\n",
    "                for row in sub_df.itertuples(index=False):\n",
    "                    pre = row.pre\n",
    "                    w = row.weight\n",
    "                    if pre in path:\n",
    "                        continue\n",
    "                    new_backward.append((path + [pre], weights + [w]))\n",
    "            backward = new_backward\n",
    "            backward_depth += 1\n",
    "    return []  # No path found within the allowed maximum steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9aa26eda-459d-4804-a427-0554246f3a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def automate_bidirectional_paths(sources, target, max_steps=6, weight_threshold=5, min_steps=2):\n",
    "    \"\"\"\n",
    "    For each source neuron in a list, run bidirectional search to find candidate pathways to the target.\n",
    "    \n",
    "    Returns:\n",
    "      A list of dictionaries. Each dictionary represents one found path with the following keys:\n",
    "         - 'source': the source neuron ID.\n",
    "         - 'target': the target neuron ID.\n",
    "         - 'path': the raw list (as a string) of neuron IDs from source to target.\n",
    "         - 'formatted_path': a formatted string representation of the pathway.\n",
    "         - 'weights': the list (as a string) of connection weights.\n",
    "         - 'steps': the number of edges in the path.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for source in tqdm(sources, desc=\"Processing sources\"):\n",
    "        candidate_paths = find_bidirectional_paths(source, target, max_steps, weight_threshold, min_steps)\n",
    "        if not candidate_paths:\n",
    "            results.append({\n",
    "                'source': source,\n",
    "                'target': target,\n",
    "                'path': \"\",\n",
    "                'formatted_path': \"No valid path found\",\n",
    "                'weights': \"\",\n",
    "                'steps': 0\n",
    "            })\n",
    "        else:\n",
    "            for path, weights in candidate_paths:\n",
    "                formatted = \"\"\n",
    "                for i, neuron in enumerate(path):\n",
    "                    if i == 0:\n",
    "                        formatted += str(neuron)\n",
    "                    else:\n",
    "                        formatted += \" ->(\" + str(weights[i-1]) + \")-> \" + str(neuron)\n",
    "                results.append({\n",
    "                    'source': source,\n",
    "                    'target': target,\n",
    "                    'path': str(path),\n",
    "                    'formatted_path': formatted,\n",
    "                    'weights': str(weights),\n",
    "                    'steps': len(path) - 1\n",
    "                })\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86a749b1-f859-44cc-8d8f-4866e0cbe417",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_automation_results_to_csv(results, file_name='automated_bidirectional_paths.csv'):\n",
    "    \"\"\"\n",
    "    Save the automation results to a CSV file.\n",
    "    \n",
    "    Each row will contain:\n",
    "      - 'source': the source neuron ID (prefixed with a ' to preserve formatting in Excel).\n",
    "      - 'target': the target neuron ID (prefixed with a ' to preserve formatting in Excel).\n",
    "      - 'path': the raw list (as a string) of neuron IDs from source to target.\n",
    "      - 'formatted_path': a human-readable string representing the pathway.\n",
    "      - 'weights': the list (as a string) of connection weights.\n",
    "      - 'steps': the number of edges (steps) in the path.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(results)\n",
    "    # Prepend a single quote (') to preserve the long numeric strings in Excel.\n",
    "    df['source'] = \"'\" + df['source'].astype(str)\n",
    "    df['target'] = \"'\" + df['target'].astype(str)\n",
    "    \n",
    "    df.to_csv(file_name, index=False)\n",
    "    print(f\"Automated candidate paths saved to {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a62edddd-073d-4c58-8ff1-05450345fafe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sources:   0%|                                 | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using materialization version 1002.\n",
      "Using materialization version 1002.\n",
      "Using materialization version 1002.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "494da4e74abc4d1ea44b3f65f41bc3b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching connectivity:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sources: 100%|█████████████████████████| 1/1 [00:06<00:00,  6.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automated candidate paths saved to automated_bidirectional_paths.csv\n",
      "{'source': 720575940623617973, 'target': 720575940634984800, 'path': '[720575940623617973, 720575940631997767, 720575940624899767, 720575940634984800]', 'formatted_path': '720575940623617973 ->(27)-> 720575940631997767 ->(7)-> 720575940624899767 ->(41)-> 720575940634984800', 'weights': '[27, 7, 41]', 'steps': 3}\n",
      "{'source': 720575940623617973, 'target': 720575940634984800, 'path': '[720575940623617973, 720575940622658317, 720575940624899767, 720575940634984800]', 'formatted_path': '720575940623617973 ->(48)-> 720575940622658317 ->(13)-> 720575940624899767 ->(41)-> 720575940634984800', 'weights': '[48, 13, 41]', 'steps': 3}\n",
      "{'source': 720575940623617973, 'target': 720575940634984800, 'path': '[720575940623617973, 720575940622658317, 720575940644609440, 720575940634984800]', 'formatted_path': '720575940623617973 ->(48)-> 720575940622658317 ->(5)-> 720575940644609440 ->(29)-> 720575940634984800', 'weights': '[48, 5, 29]', 'steps': 3}\n",
      "{'source': 720575940623617973, 'target': 720575940634984800, 'path': '[720575940623617973, 720575940622658317, 720575940645975063, 720575940634984800]', 'formatted_path': '720575940623617973 ->(48)-> 720575940622658317 ->(25)-> 720575940645975063 ->(11)-> 720575940634984800', 'weights': '[48, 25, 11]', 'steps': 3}\n",
      "{'source': 720575940623617973, 'target': 720575940634984800, 'path': '[720575940623617973, 720575940613043861, 720575940614871106, 720575940634984800]', 'formatted_path': '720575940623617973 ->(15)-> 720575940613043861 ->(5)-> 720575940614871106 ->(9)-> 720575940634984800', 'weights': '[15, 5, 9]', 'steps': 3}\n",
      "{'source': 720575940623617973, 'target': 720575940634984800, 'path': '[720575940623617973, 720575940635229335, 720575940614871106, 720575940634984800]', 'formatted_path': '720575940623617973 ->(50)-> 720575940635229335 ->(6)-> 720575940614871106 ->(9)-> 720575940634984800', 'weights': '[50, 6, 9]', 'steps': 3}\n",
      "{'source': 720575940623617973, 'target': 720575940634984800, 'path': '[720575940623617973, 720575940623912636, 720575940622228999, 720575940634984800]', 'formatted_path': '720575940623617973 ->(7)-> 720575940623912636 ->(6)-> 720575940622228999 ->(33)-> 720575940634984800', 'weights': '[7, 6, 33]', 'steps': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Example list of source neurons (your \"A1\" list)\n",
    "    sources = [\n",
    "        720575940623617973, #VP5 PN\n",
    "        # Add more source neuron IDs as needed.\n",
    "    ]\n",
    "    \n",
    "    # The target neuron (B1)\n",
    "    target = 720575940634984800 #LNd6\n",
    "\n",
    "    # Run the automated bidirectional search with progress tracking.\n",
    "    results = automate_bidirectional_paths(sources, target, max_steps=6, weight_threshold=5, min_steps=2)\n",
    "    \n",
    "    # Save the results to a CSV file.\n",
    "    save_automation_results_to_csv(results, file_name='automated_bidirectional_paths.csv')\n",
    "    \n",
    "    # Optionally, print the results.\n",
    "    for row in results:\n",
    "        print(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (fafbseg_env)",
   "language": "python",
   "name": "fafbseg_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
